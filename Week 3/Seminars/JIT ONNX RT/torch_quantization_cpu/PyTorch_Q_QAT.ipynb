{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EENlZvOtPDZ6"
   },
   "source": [
    "# Туториал по квантованию с помощью интструментов PyTorch\n",
    "\n",
    "В этом туториале рассмотрим, как выполнить статическое квантование после обучения, а также разберем два более продвинутых метода — квантование по каналам и обучение с учетом квантования (QAT - Quantization Aware Training) — для дальнейшего повышения точности модели. <br> \n",
    "\n",
    "Рассмотрим все на примере задачи MNIST с помощью простой архитектуры LeNet. \n",
    "\n",
    "\n",
    "Данный туториал достаточно мимиалистичен для теории и более глубоких объяснений того, что на самом деле происходит, я бы рекомендовал ознакомиться с: [Квантование глубоких сверточных сетей для эффективного инференса\n",
    "](https://arxiv.org/abs/1806.08342).\n",
    "\n",
    "Туториал в значительной степени адаптирован из: https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTvIwDlYvBzC"
   },
   "source": [
    "### Начало \n",
    "\n",
    "Перед началом квантования мы импортируем набор данных MNIST и обучим простую сверточную нейронную сеть (CNN) для задачи классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hbiiMcdNJI--"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch==1.5.0 torchvision==1.6.0\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaMDWYArEXO"
   },
   "source": [
    "Загрузим обучающие и тестовые данные, применим нормализацию и преобразования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "4ef3ac3a55b1405cbbfb495d511f8c57",
      "63735be95ec2408abd58846e255a7547",
      "09c7204e26a44c95872da1e227c30315",
      "1d71085620904406b58384c3bb0b1edf",
      "31805a8fbfde40cc9867a3643e829a44",
      "e65e31421f9b40d4a3c59f36622e3163",
      "485835aae0cf48feac7afade58a6a521",
      "502a360a8774499c8b9a950c34a684e5",
      "c1d10c7a472146e6bc09d22632fd848e",
      "a5171886b4bc4c67b758ce052c1cee77",
      "deb6986103c4477cad2b07f7a5ea4974",
      "a1653abe0c694d5d8676a4c09bfe5800",
      "b18f211b24934aba92ec6c43d564061c",
      "90a2ffa504ff42329da39e7c1497c888",
      "1fba5940cf064fa68317af9792da8c3b",
      "88accd52e8fe4ccd8907edf082b47d97",
      "f9f8b1e0739844809134cba5ab30e74d",
      "4722aa0e04264c76964d58b5e3a65a32",
      "dec70d900ac442138b73f1d58da684af",
      "f369bec9f8ff41338384dd48065e2d59",
      "3f37affbd69e486dad7cddeb8c8c9cb5",
      "84107f986d5b45bfb4d9a9c9f934d1de",
      "4725f0f119e04f81a780a2489a8ef8dd",
      "ce6dcf9416d141c9b5d5ad1e6394b621",
      "a4a8ee6bf1da4549a0e1fcfdba392b17",
      "aaf6e3a398a84014ad173b40d54a1a45",
      "777a4203229d4a00b9dbf1e7603e0d36",
      "093c877eaa43432eabc2aa71c7f2b587",
      "5840df2790f24f2c9c8d4d8427a2922b",
      "3c122842f89b418cbf2133d83e5ff48e",
      "1c08dece76594deea344614336c0991d",
      "24c95a6a11b449c0b4c698ce5bdda18b"
     ]
    },
    "id": "_5UuOjjrnogR",
    "outputId": "84bb5a95-be28-428d-e2b5-4ff5b03b8aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:07<00:00, 1372179.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 209783.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1740526.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1633836.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5qXPDxnUnj"
   },
   "source": [
    "Определим некоторые вспомогательные функции и классы, которые помогут нам отслеживать статистики и качество работы модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WetzHpQybN1k",
    "outputId": "f772c10f-da62-46c7-ccdb-c217a34f9a3d"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def accuracy(output, target):\n",
    "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
    "        return correct_one.mul_(100.0 / batch_size).item()\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "def load_model(quantized_model, model):\n",
    "    \"\"\" Loads in the weights into an object meant for quantization \"\"\"\n",
    "    state_dict = model.state_dict()\n",
    "    model = model.to('cpu')\n",
    "    quantized_model.load_state_dict(state_dict)\n",
    "\n",
    "def fuse_modules(model):\n",
    "    \"\"\" Fuse together convolutions/linear layers and ReLU \"\"\"\n",
    "    torch.quantization.fuse_modules(model, [['conv1', 'relu1'],\n",
    "                                            ['conv2', 'relu2'],\n",
    "                                            ['fc1', 'relu3'],\n",
    "                                            ['fc2', 'relu4']], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l62CkyIwtSOv"
   },
   "source": [
    "Определим простую сверточную нейронную сеть, для классификации изображений MNIST. <br>\n",
    "\n",
    "Уделите внимание на части  'QuantStub()' и 'DeQuantStub()' это служебные функции для того что бы определить где у нас начинается, а где заканчивается квантование.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9fL3F-7Rntog"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, q = False):\n",
    "        # By turning on Q we can turn on/off the quantization\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256, 120, bias=False)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
    "        self.q = q\n",
    "        if q:\n",
    "          self.quant = QuantStub()\n",
    "          self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.q:\n",
    "          x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        # Be careful to use reshape here instead of view\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        if self.q:\n",
    "          x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "W9_LdxSTb3BJ",
    "outputId": "b5223438-8aed-4612-f040-120188d23e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.179057\n"
     ]
    }
   ],
   "source": [
    "net = Net(q=False).cuda()\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nijieuxptag6"
   },
   "source": [
    "Обучим эту модель на обучающем наборе данных (это может занять несколько минут)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CzK6ohj5oNCT"
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module, dataloader: DataLoader, cuda=False, q=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    model.train()\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = AverageMeter('loss')\n",
    "        acc = AverageMeter('train_acc')\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if epoch>=3 and q:\n",
    "              model.apply(torch.quantization.disable_observer)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss.update(loss.item(), outputs.shape[0])\n",
    "            acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
    "            if i % 100 == 0:    # print every 100 mini-batches\n",
    "                print('[%d, %5d] ' %\n",
    "                    (epoch + 1, i + 1), running_loss, acc)\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HixhBHaqtmZU",
    "outputId": "60a4467f-d04f-4e89-edb6-80d33dafaa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1]  loss 2.303799 (2.303799) train_acc 3.125000 (3.125000)\n",
      "[1,   101]  loss 2.293097 (2.302622) train_acc 20.312500 (7.967203)\n",
      "[1,   201]  loss 2.288037 (2.298191) train_acc 29.687500 (14.995336)\n",
      "[1,   301]  loss 2.281747 (2.293290) train_acc 32.812500 (20.276163)\n",
      "[1,   401]  loss 2.243036 (2.285806) train_acc 53.125000 (25.027276)\n",
      "[1,   501]  loss 2.197001 (2.273354) train_acc 43.750000 (28.686377)\n",
      "[1,   601]  loss 1.899132 (2.245754) train_acc 57.812500 (31.863561)\n",
      "[1,   701]  loss 1.420953 (2.168343) train_acc 68.750000 (35.362429)\n",
      "[1,   801]  loss 0.756028 (2.025936) train_acc 79.687500 (39.965668)\n",
      "[1,   901]  loss 0.594413 (1.869885) train_acc 82.812500 (44.681257)\n",
      "[2,     1]  loss 0.679886 (0.679886) train_acc 76.562500 (76.562500)\n",
      "[2,   101]  loss 0.301674 (0.434280) train_acc 90.625000 (86.772896)\n",
      "[2,   201]  loss 0.290412 (0.398816) train_acc 89.062500 (88.184080)\n",
      "[2,   301]  loss 0.416183 (0.365731) train_acc 90.625000 (89.135174)\n",
      "[2,   401]  loss 0.417450 (0.345215) train_acc 90.625000 (89.717113)\n",
      "[2,   501]  loss 0.223687 (0.324316) train_acc 93.750000 (90.322480)\n",
      "[2,   601]  loss 0.336908 (0.307662) train_acc 84.375000 (90.791389)\n",
      "[2,   701]  loss 0.237725 (0.294511) train_acc 87.500000 (91.191155)\n",
      "[2,   801]  loss 0.232959 (0.283726) train_acc 90.625000 (91.535971)\n",
      "[2,   901]  loss 0.027858 (0.273169) train_acc 100.000000 (91.840663)\n",
      "[3,     1]  loss 0.156995 (0.156995) train_acc 95.312500 (95.312500)\n",
      "[3,   101]  loss 0.131824 (0.182199) train_acc 95.312500 (94.647277)\n",
      "[3,   201]  loss 0.134160 (0.173127) train_acc 95.312500 (94.783893)\n",
      "[3,   301]  loss 0.099695 (0.165923) train_acc 98.437500 (94.980274)\n",
      "[3,   401]  loss 0.240809 (0.165494) train_acc 92.187500 (94.957918)\n",
      "[3,   501]  loss 0.084055 (0.164288) train_acc 96.875000 (95.034930)\n",
      "[3,   601]  loss 0.355246 (0.160332) train_acc 92.187500 (95.169509)\n",
      "[3,   701]  loss 0.172202 (0.156689) train_acc 95.312500 (95.245631)\n",
      "[3,   801]  loss 0.080023 (0.154585) train_acc 96.875000 (95.324204)\n",
      "[3,   901]  loss 0.302593 (0.150821) train_acc 90.625000 (95.430425)\n",
      "[4,     1]  loss 0.202497 (0.202497) train_acc 90.625000 (90.625000)\n",
      "[4,   101]  loss 0.182182 (0.132997) train_acc 93.750000 (95.792079)\n",
      "[4,   201]  loss 0.011869 (0.124046) train_acc 100.000000 (96.190920)\n",
      "[4,   301]  loss 0.090456 (0.126645) train_acc 95.312500 (96.127492)\n",
      "[4,   401]  loss 0.058218 (0.121407) train_acc 98.437500 (96.255455)\n",
      "[4,   501]  loss 0.063973 (0.121228) train_acc 98.437500 (96.304266)\n",
      "[4,   601]  loss 0.050758 (0.119523) train_acc 100.000000 (96.360233)\n",
      "[4,   701]  loss 0.167158 (0.119218) train_acc 95.312500 (96.384629)\n",
      "[4,   801]  loss 0.050867 (0.117701) train_acc 100.000000 (96.416589)\n",
      "[4,   901]  loss 0.050459 (0.115180) train_acc 98.437500 (96.507353)\n",
      "[5,     1]  loss 0.059028 (0.059028) train_acc 98.437500 (98.437500)\n",
      "[5,   101]  loss 0.116530 (0.103565) train_acc 95.312500 (96.689356)\n",
      "[5,   201]  loss 0.095784 (0.099824) train_acc 96.875000 (96.789490)\n",
      "[5,   301]  loss 0.072126 (0.099165) train_acc 96.875000 (96.880191)\n",
      "[5,   401]  loss 0.062504 (0.097422) train_acc 98.437500 (96.980206)\n",
      "[5,   501]  loss 0.102805 (0.096587) train_acc 98.437500 (97.027819)\n",
      "[5,   601]  loss 0.050847 (0.095479) train_acc 98.437500 (97.082987)\n",
      "[5,   701]  loss 0.016977 (0.095987) train_acc 100.000000 (97.073377)\n",
      "[5,   801]  loss 0.076279 (0.095575) train_acc 96.875000 (97.107132)\n",
      "[5,   901]  loss 0.018512 (0.095606) train_acc 100.000000 (97.086570)\n",
      "[6,     1]  loss 0.035985 (0.035985) train_acc 100.000000 (100.000000)\n",
      "[6,   101]  loss 0.097938 (0.082647) train_acc 96.875000 (97.339109)\n",
      "[6,   201]  loss 0.032035 (0.083924) train_acc 98.437500 (97.388060)\n",
      "[6,   301]  loss 0.133899 (0.087284) train_acc 96.875000 (97.311047)\n",
      "[6,   401]  loss 0.057260 (0.087055) train_acc 96.875000 (97.346478)\n",
      "[6,   501]  loss 0.101439 (0.086311) train_acc 93.750000 (97.311627)\n",
      "[6,   601]  loss 0.128565 (0.086053) train_acc 96.875000 (97.319572)\n",
      "[6,   701]  loss 0.095548 (0.085097) train_acc 95.312500 (97.365371)\n",
      "[6,   801]  loss 0.058769 (0.083596) train_acc 98.437500 (97.423143)\n",
      "[6,   901]  loss 0.046080 (0.083583) train_acc 98.437500 (97.419534)\n",
      "[7,     1]  loss 0.134855 (0.134855) train_acc 95.312500 (95.312500)\n",
      "[7,   101]  loss 0.061718 (0.072691) train_acc 98.437500 (97.834158)\n",
      "[7,   201]  loss 0.015512 (0.074213) train_acc 100.000000 (97.706779)\n",
      "[7,   301]  loss 0.077117 (0.075505) train_acc 96.875000 (97.601744)\n",
      "[7,   401]  loss 0.055943 (0.076618) train_acc 98.437500 (97.615337)\n",
      "[7,   501]  loss 0.011157 (0.077271) train_acc 100.000000 (97.639097)\n",
      "[7,   601]  loss 0.049844 (0.076874) train_acc 98.437500 (97.636751)\n",
      "[7,   701]  loss 0.072434 (0.076931) train_acc 98.437500 (97.639533)\n",
      "[7,   801]  loss 0.086152 (0.075337) train_acc 95.312500 (97.666979)\n",
      "[7,   901]  loss 0.023854 (0.075226) train_acc 98.437500 (97.658851)\n",
      "[8,     1]  loss 0.063871 (0.063871) train_acc 98.437500 (98.437500)\n",
      "[8,   101]  loss 0.037358 (0.067195) train_acc 98.437500 (97.834158)\n",
      "[8,   201]  loss 0.054007 (0.069215) train_acc 98.437500 (97.846704)\n",
      "[8,   301]  loss 0.119236 (0.069333) train_acc 95.312500 (97.882060)\n",
      "[8,   401]  loss 0.075045 (0.070526) train_acc 98.437500 (97.864713)\n",
      "[8,   501]  loss 0.045030 (0.069085) train_acc 98.437500 (97.891717)\n",
      "[8,   601]  loss 0.055860 (0.069909) train_acc 98.437500 (97.873336)\n",
      "[8,   701]  loss 0.135934 (0.070347) train_acc 95.312500 (97.875802)\n",
      "[8,   801]  loss 0.014121 (0.069080) train_acc 100.000000 (97.912765)\n",
      "[8,   901]  loss 0.045204 (0.068608) train_acc 98.437500 (97.906840)\n",
      "[9,     1]  loss 0.156182 (0.156182) train_acc 96.875000 (96.875000)\n",
      "[9,   101]  loss 0.039229 (0.070558) train_acc 98.437500 (97.803218)\n",
      "[9,   201]  loss 0.051607 (0.064576) train_acc 98.437500 (98.009950)\n",
      "[9,   301]  loss 0.066651 (0.064619) train_acc 96.875000 (97.965116)\n",
      "[9,   401]  loss 0.061618 (0.063467) train_acc 96.875000 (98.032263)\n",
      "[9,   501]  loss 0.052474 (0.062510) train_acc 98.437500 (98.032061)\n",
      "[9,   601]  loss 0.011743 (0.062022) train_acc 100.000000 (98.031926)\n",
      "[9,   701]  loss 0.070861 (0.062109) train_acc 96.875000 (98.038516)\n",
      "[9,   801]  loss 0.125564 (0.063072) train_acc 96.875000 (98.000546)\n",
      "[9,   901]  loss 0.030367 (0.062290) train_acc 100.000000 (98.040372)\n",
      "[10,     1]  loss 0.024716 (0.024716) train_acc 100.000000 (100.000000)\n",
      "[10,   101]  loss 0.081435 (0.054873) train_acc 95.312500 (98.298267)\n",
      "[10,   201]  loss 0.019781 (0.056171) train_acc 100.000000 (98.250933)\n",
      "[10,   301]  loss 0.152270 (0.056277) train_acc 98.437500 (98.235050)\n",
      "[10,   401]  loss 0.037331 (0.057941) train_acc 98.437500 (98.188123)\n",
      "[10,   501]  loss 0.046594 (0.057024) train_acc 98.437500 (98.225424)\n",
      "[10,   601]  loss 0.107354 (0.057079) train_acc 96.875000 (98.250312)\n",
      "[10,   701]  loss 0.018778 (0.056766) train_acc 100.000000 (98.261412)\n",
      "[10,   801]  loss 0.021470 (0.057040) train_acc 100.000000 (98.242431)\n",
      "[10,   901]  loss 0.022330 (0.057929) train_acc 100.000000 (98.212056)\n",
      "[11,     1]  loss 0.010195 (0.010195) train_acc 100.000000 (100.000000)\n",
      "[11,   101]  loss 0.012874 (0.050659) train_acc 100.000000 (98.561262)\n",
      "[11,   201]  loss 0.064786 (0.053971) train_acc 96.875000 (98.351990)\n",
      "[11,   301]  loss 0.085288 (0.052948) train_acc 98.437500 (98.354444)\n",
      "[11,   401]  loss 0.007267 (0.053224) train_acc 100.000000 (98.340087)\n",
      "[11,   501]  loss 0.102508 (0.053371) train_acc 96.875000 (98.306512)\n",
      "[11,   601]  loss 0.104789 (0.053947) train_acc 96.875000 (98.294509)\n",
      "[11,   701]  loss 0.092829 (0.053496) train_acc 98.437500 (98.305991)\n",
      "[11,   801]  loss 0.068846 (0.054085) train_acc 96.875000 (98.306804)\n",
      "[11,   901]  loss 0.004902 (0.053668) train_acc 100.000000 (98.329981)\n",
      "[12,     1]  loss 0.043296 (0.043296) train_acc 98.437500 (98.437500)\n",
      "[12,   101]  loss 0.076791 (0.051477) train_acc 95.312500 (98.360149)\n",
      "[12,   201]  loss 0.157782 (0.051005) train_acc 96.875000 (98.320896)\n",
      "[12,   301]  loss 0.046322 (0.051617) train_acc 98.437500 (98.370017)\n",
      "[12,   401]  loss 0.037868 (0.053723) train_acc 98.437500 (98.359570)\n",
      "[12,   501]  loss 0.042940 (0.052585) train_acc 96.875000 (98.406312)\n",
      "[12,   601]  loss 0.060186 (0.052426) train_acc 96.875000 (98.401102)\n",
      "[12,   701]  loss 0.042321 (0.051368) train_acc 98.437500 (98.424126)\n",
      "[12,   801]  loss 0.014761 (0.051225) train_acc 100.000000 (98.441401)\n",
      "[12,   901]  loss 0.031574 (0.050750) train_acc 100.000000 (98.466981)\n",
      "[13,     1]  loss 0.017718 (0.017718) train_acc 100.000000 (100.000000)\n",
      "[13,   101]  loss 0.021784 (0.049832) train_acc 100.000000 (98.406559)\n",
      "[13,   201]  loss 0.030408 (0.050018) train_acc 100.000000 (98.460821)\n",
      "[13,   301]  loss 0.137119 (0.049537) train_acc 98.437500 (98.447882)\n",
      "[13,   401]  loss 0.059972 (0.050602) train_acc 96.875000 (98.394638)\n",
      "[13,   501]  loss 0.011564 (0.049994) train_acc 100.000000 (98.425025)\n",
      "[13,   601]  loss 0.033367 (0.049193) train_acc 98.437500 (98.466098)\n",
      "[13,   701]  loss 0.039850 (0.048936) train_acc 98.437500 (98.495453)\n",
      "[13,   801]  loss 0.006499 (0.048965) train_acc 100.000000 (98.492119)\n",
      "[13,   901]  loss 0.025048 (0.048523) train_acc 98.437500 (98.499931)\n",
      "[14,     1]  loss 0.077931 (0.077931) train_acc 96.875000 (96.875000)\n",
      "[14,   101]  loss 0.068737 (0.047538) train_acc 98.437500 (98.452970)\n",
      "[14,   201]  loss 0.018014 (0.046664) train_acc 98.437500 (98.476368)\n",
      "[14,   301]  loss 0.021850 (0.047305) train_acc 98.437500 (98.504983)\n",
      "[14,   401]  loss 0.083337 (0.047069) train_acc 96.875000 (98.495948)\n",
      "[14,   501]  loss 0.003775 (0.047878) train_acc 100.000000 (98.487400)\n",
      "[14,   601]  loss 0.062373 (0.046970) train_acc 96.875000 (98.536294)\n",
      "[14,   701]  loss 0.009890 (0.046413) train_acc 100.000000 (98.544490)\n",
      "[14,   801]  loss 0.046696 (0.045042) train_acc 98.437500 (98.587703)\n",
      "[14,   901]  loss 0.028001 (0.044956) train_acc 98.437500 (98.577969)\n",
      "[15,     1]  loss 0.028859 (0.028859) train_acc 100.000000 (100.000000)\n",
      "[15,   101]  loss 0.018797 (0.042814) train_acc 98.437500 (98.731436)\n",
      "[15,   201]  loss 0.042533 (0.042226) train_acc 98.437500 (98.779540)\n",
      "[15,   301]  loss 0.037943 (0.042776) train_acc 100.000000 (98.697051)\n",
      "[15,   401]  loss 0.019912 (0.042175) train_acc 98.437500 (98.679084)\n",
      "[15,   501]  loss 0.078325 (0.042538) train_acc 96.875000 (98.677645)\n",
      "[15,   601]  loss 0.008396 (0.042959) train_acc 100.000000 (98.642887)\n",
      "[15,   701]  loss 0.004752 (0.042139) train_acc 100.000000 (98.660396)\n",
      "[15,   801]  loss 0.045019 (0.042632) train_acc 98.437500 (98.640371)\n",
      "[15,   901]  loss 0.079051 (0.042869) train_acc 98.437500 (98.640400)\n",
      "[16,     1]  loss 0.054177 (0.054177) train_acc 96.875000 (96.875000)\n",
      "[16,   101]  loss 0.053261 (0.044676) train_acc 98.437500 (98.715965)\n",
      "[16,   201]  loss 0.069553 (0.042331) train_acc 95.312500 (98.740672)\n",
      "[16,   301]  loss 0.031958 (0.042508) train_acc 98.437500 (98.697051)\n",
      "[16,   401]  loss 0.064139 (0.041998) train_acc 96.875000 (98.745324)\n",
      "[16,   501]  loss 0.062824 (0.041510) train_acc 98.437500 (98.743139)\n",
      "[16,   601]  loss 0.056452 (0.041362) train_acc 98.437500 (98.741681)\n",
      "[16,   701]  loss 0.023631 (0.041728) train_acc 98.437500 (98.713891)\n",
      "[16,   801]  loss 0.018247 (0.041854) train_acc 100.000000 (98.693040)\n",
      "[16,   901]  loss 0.050982 (0.041254) train_acc 98.437500 (98.704564)\n",
      "[17,     1]  loss 0.077597 (0.077597) train_acc 95.312500 (95.312500)\n",
      "[17,   101]  loss 0.011729 (0.042896) train_acc 100.000000 (98.576733)\n",
      "[17,   201]  loss 0.012027 (0.038379) train_acc 100.000000 (98.771766)\n",
      "[17,   301]  loss 0.010699 (0.037478) train_acc 100.000000 (98.790490)\n",
      "[17,   401]  loss 0.049417 (0.038374) train_acc 98.437500 (98.772600)\n",
      "[17,   501]  loss 0.038987 (0.038517) train_acc 98.437500 (98.746257)\n",
      "[17,   601]  loss 0.050898 (0.038826) train_acc 96.875000 (98.741681)\n",
      "[17,   701]  loss 0.007011 (0.039014) train_acc 100.000000 (98.754012)\n",
      "[17,   801]  loss 0.007750 (0.038632) train_acc 100.000000 (98.788624)\n",
      "[17,   901]  loss 0.024692 (0.038509) train_acc 100.000000 (98.817286)\n",
      "[18,     1]  loss 0.020318 (0.020318) train_acc 100.000000 (100.000000)\n",
      "[18,   101]  loss 0.003879 (0.032082) train_acc 100.000000 (98.917079)\n",
      "[18,   201]  loss 0.021031 (0.033415) train_acc 98.437500 (98.950560)\n",
      "[18,   301]  loss 0.028038 (0.032132) train_acc 98.437500 (98.998131)\n",
      "[18,   401]  loss 0.026311 (0.033235) train_acc 100.000000 (98.963529)\n",
      "[18,   501]  loss 0.079638 (0.035912) train_acc 98.437500 (98.908433)\n",
      "[18,   601]  loss 0.019440 (0.037075) train_acc 100.000000 (98.856073)\n",
      "[18,   701]  loss 0.040239 (0.037036) train_acc 98.437500 (98.836484)\n",
      "[18,   801]  loss 0.000946 (0.036884) train_acc 100.000000 (98.849095)\n",
      "[18,   901]  loss 0.013929 (0.036700) train_acc 100.000000 (98.853704)\n",
      "[19,     1]  loss 0.036981 (0.036981) train_acc 98.437500 (98.437500)\n",
      "[19,   101]  loss 0.029648 (0.031091) train_acc 98.437500 (99.071782)\n",
      "[19,   201]  loss 0.076819 (0.033289) train_acc 95.312500 (98.942786)\n",
      "[19,   301]  loss 0.010713 (0.034895) train_acc 100.000000 (98.889120)\n",
      "[19,   401]  loss 0.039371 (0.034900) train_acc 98.437500 (98.908978)\n",
      "[19,   501]  loss 0.017058 (0.034324) train_acc 100.000000 (98.930264)\n",
      "[19,   601]  loss 0.051594 (0.034601) train_acc 98.437500 (98.941868)\n",
      "[19,   701]  loss 0.003819 (0.034914) train_acc 100.000000 (98.930100)\n",
      "[19,   801]  loss 0.013828 (0.035131) train_acc 98.437500 (98.931024)\n",
      "[19,   901]  loss 0.029785 (0.035247) train_acc 98.437500 (98.923072)\n",
      "[20,     1]  loss 0.034520 (0.034520) train_acc 98.437500 (98.437500)\n",
      "[20,   101]  loss 0.048896 (0.031825) train_acc 98.437500 (99.102723)\n",
      "[20,   201]  loss 0.020869 (0.032534) train_acc 98.437500 (99.004975)\n",
      "[20,   301]  loss 0.106281 (0.032824) train_acc 98.437500 (98.992940)\n",
      "[20,   401]  loss 0.027782 (0.033459) train_acc 98.437500 (98.975218)\n",
      "[20,   501]  loss 0.045534 (0.033407) train_acc 96.875000 (98.973927)\n",
      "[20,   601]  loss 0.048132 (0.033443) train_acc 98.437500 (98.967866)\n",
      "[20,   701]  loss 0.015795 (0.033523) train_acc 100.000000 (98.981366)\n",
      "[20,   801]  loss 0.070767 (0.033522) train_acc 98.437500 (98.977840)\n",
      "[20,   901]  loss 0.104845 (0.033067) train_acc 98.437500 (98.992439)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, trainloader, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJggxnCVuRxU"
   },
   "source": [
    "Теперь, когда CNN обучена, давайте проверим ее на нашем тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "y27_n-djuEdz",
    "outputId": "ec5b6136-ca04-4ba0-d591-e19229d6ec24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 98.48% - FP32\n"
     ]
    }
   ],
   "source": [
    "score = test(net, testloader, cuda=True)\n",
    "print('Accuracy of the network on the test images: {}% - FP32'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Lp-ElDsrKua"
   },
   "source": [
    "###  Квантование после обучения - Post-training quantization PTQ\n",
    "\n",
    "\n",
    "Определим новую архитектуру квантованной сети, где мы также определяем заглушки квантования и деквантования, которые будут важны в начале и в конце.\n",
    "\n",
    "Далее мы «объединим модули»; это может сделать модель быстрее за счет более оптимального распределения вычислений в памяти. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "X-nQWDXrhItv"
   },
   "outputs": [],
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "wQQRNAEGYVUe",
    "outputId": "596f0caf-1be9-471f-8473-4e3df00d66d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.179249\n",
      "Accuracy of the fused network on the test images: 98.48% - FP32\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(qnet)\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused network on the test images: {}% - FP32'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiaQkj6wJuC6"
   },
   "source": [
    "Post-training static квантование   включает в себя не только преобразование весов из float в int, как при динамическом квантовании, но и выполнение дополнительного шага калибровки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "x-ZaMV4bUb6-",
    "outputId": "37a7ada4-2f61-4b57-80da-836c3e1ab469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Conv1: After observer insertion \n",
      "\n",
      " ConvReLU2d(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (1): ReLU()\n",
      "  (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      ")\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.055810220539569855, zero_point=0, bias=False)\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n"
     ]
    }
   ],
   "source": [
    "qnet.qconfig = torch.quantization.default_qconfig\n",
    "print(qnet.qconfig)\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
    "\n",
    "# Важный этап - калибровка модели\n",
    "test(qnet, trainloader, cuda=False)\n",
    "\n",
    "\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wbDvGBtMavCO",
    "outputId": "2b9f7749-3905-4f3d-bbec-1d87ac6299ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the fused and quantized network on the test images: 98.67% - INT8\n"
     ]
    }
   ],
   "source": [
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcv6Gi45lZ4L"
   },
   "source": [
    "Мы также можем определить пользовательскую конфигурацию квантования, в которой мы заменяем наблюдателей (observers) по умолчанию и вместо квантования по максимуму/минимуму можем взять среднее значение наблюдаемых значений, что, как мы надеемся, обеспечит лучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "qNj6TNFu1ljn",
    "outputId": "9e9db78b-dd1b-4b43-b0dc-718d5d8491c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Post Training Quantization Prepare: Inserting Observers\n",
      "\n",
      " Conv1: After observer insertion \n",
      "\n",
      " ConvReLU2d(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (1): ReLU()\n",
      "  (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.055435553193092346, zero_point=0, bias=False)\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n",
      "Accuracy of the fused and quantized network on the test images: 98.45% - INT8\n"
     ]
    }
   ],
   "source": [
    "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
    "\n",
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)\n",
    "\n",
    "qnet.qconfig = torch.quantization.QConfig(\n",
    "                                      activation=MovingAverageMinMaxObserver.with_args(reduce_range=True),\n",
    "                                      weight=MovingAverageMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "print(qnet.qconfig)\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
    "\n",
    "# Важный этап - калибровка модели\n",
    "test(qnet, trainloader, cuda=False)\n",
    "\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LXNCT7fgcMx"
   },
   "source": [
    "Кроме того, мы можем значительно улучшить точность, просто используя другую конфигурацию квантования. Мы повторяем то же упражнение с рекомендуемой конфигурацией для квантования для архитектур x86. Эта конфигурация делает следующее:\n",
    "Квантует веса на основе каждого канала. Она\n",
    "использует наблюдателя гистограммы, который собирает гистограмму активаций, а затем выбирает параметры квантования оптимальным образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nZq5yF_gWBs"
   },
   "outputs": [],
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, net)\n",
    "fuse_modules(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "HXv5pAwVlGFh",
    "outputId": "d7119fc5-7aef-4da4-8f9a-1de9705b086f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "Size of model after quantization\n",
      "Size (MB): 0.050084\n"
     ]
    }
   ],
   "source": [
    "qnet.qconfig = torch.quantization.get_default_qconfig('x86')\n",
    "print(qnet.qconfig)\n",
    "\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "test(qnet, trainloader, cuda=False)\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X5Vjyayimv8n",
    "outputId": "348eb6fb-0873-4a36-97c9-03da9adc1a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the fused and quantized network on the test images: 98.45% - INT8\n"
     ]
    }
   ],
   "source": [
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A_G3tsasU6U"
   },
   "source": [
    "### Обучение с учетом квантования\n",
    "\n",
    "Обучение с учетом квантования (QAT) — это метод квантования, который обычно обеспечивает наивысшую точность. При QAT все веса и активации «поддельно квантуются» во время как прямого, так и обратного проходов обучения: то есть значения float округляются для имитации значений int8, но все вычисления по-прежнему выполняются с числами с плавающей точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "o-mGba7QsXzf",
    "outputId": "a49c21e3-4c8a-4dc5-bcc7-51f360eb0863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " ConvReLU2d(\n",
      "  1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
      "  (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
      "    (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
      "  )\n",
      "  (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
      "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "qnet = Net(q=True)\n",
    "fuse_modules(qnet)\n",
    "qnet.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
    "\n",
    "torch.quantization.prepare_qat(qnet, inplace=True)\n",
    "\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "qnet=qnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mmiecLHIuRI4",
    "outputId": "d427a094-fe7c-4649-f9cb-8d22b023030b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1]  loss 2.305163 (2.305163) train_acc 9.375000 (9.375000)\n",
      "[1,   101]  loss 2.300375 (2.299719) train_acc 6.250000 (11.711015)\n",
      "[1,   201]  loss 2.289497 (2.295191) train_acc 23.437500 (15.010883)\n",
      "[1,   301]  loss 2.269218 (2.290190) train_acc 31.250000 (18.075166)\n",
      "[1,   401]  loss 2.248153 (2.283823) train_acc 54.687500 (22.143859)\n",
      "[1,   501]  loss 2.222377 (2.274365) train_acc 53.125000 (26.721557)\n",
      "[1,   601]  loss 2.166247 (2.260955) train_acc 53.125000 (30.953619)\n",
      "[1,   701]  loss 2.058138 (2.240316) train_acc 73.437500 (36.031116)\n",
      "[1,   801]  loss 1.867005 (2.208219) train_acc 78.125000 (40.802512)\n",
      "[1,   901]  loss 1.680785 (2.156148) train_acc 68.750000 (44.889359)\n",
      "[2,     1]  loss 1.385889 (1.385889) train_acc 81.250000 (81.250000)\n",
      "[2,   101]  loss 1.021710 (1.202953) train_acc 73.437500 (80.538366)\n",
      "[2,   201]  loss 0.664465 (1.006807) train_acc 79.687500 (81.980721)\n",
      "[2,   301]  loss 0.481810 (0.858740) train_acc 84.375000 (83.165490)\n",
      "[2,   401]  loss 0.324097 (0.758068) train_acc 92.187500 (84.184071)\n",
      "[2,   501]  loss 0.505921 (0.684014) train_acc 92.187500 (85.154691)\n",
      "[2,   601]  loss 0.371265 (0.627270) train_acc 89.062500 (85.973898)\n",
      "[2,   701]  loss 0.243253 (0.582176) train_acc 89.062500 (86.657454)\n",
      "[2,   801]  loss 0.150076 (0.543608) train_acc 96.875000 (87.275671)\n",
      "[2,   901]  loss 0.378556 (0.512961) train_acc 87.500000 (87.777469)\n",
      "[3,     1]  loss 0.195776 (0.195776) train_acc 93.750000 (93.750000)\n",
      "[3,   101]  loss 0.342599 (0.239441) train_acc 87.500000 (92.806312)\n",
      "[3,   201]  loss 0.296487 (0.237593) train_acc 92.187500 (92.949316)\n",
      "[3,   301]  loss 0.191713 (0.233325) train_acc 93.750000 (93.075166)\n",
      "[3,   401]  loss 0.075834 (0.224920) train_acc 98.437500 (93.231764)\n",
      "[3,   501]  loss 0.057325 (0.218983) train_acc 100.000000 (93.391342)\n",
      "[3,   601]  loss 0.138007 (0.213973) train_acc 96.875000 (93.513415)\n",
      "[3,   701]  loss 0.129680 (0.210961) train_acc 95.312500 (93.582828)\n",
      "[3,   801]  loss 0.158648 (0.206507) train_acc 95.312500 (93.728542)\n",
      "[3,   901]  loss 0.150266 (0.201218) train_acc 95.312500 (93.883532)\n",
      "[4,     1]  loss 0.100665 (0.100665) train_acc 96.875000 (96.875000)\n",
      "[4,   101]  loss 0.203309 (0.155662) train_acc 95.312500 (95.095916)\n",
      "[4,   201]  loss 0.245550 (0.149997) train_acc 92.187500 (95.304726)\n",
      "[4,   301]  loss 0.108782 (0.149488) train_acc 93.750000 (95.385174)\n",
      "[4,   401]  loss 0.069070 (0.147567) train_acc 98.437500 (95.499532)\n",
      "[4,   501]  loss 0.172511 (0.144530) train_acc 95.312500 (95.621257)\n",
      "[4,   601]  loss 0.119242 (0.142710) train_acc 95.312500 (95.681676)\n",
      "[4,   701]  loss 0.087355 (0.141990) train_acc 96.875000 (95.655760)\n",
      "[4,   801]  loss 0.087462 (0.140038) train_acc 95.312500 (95.720194)\n",
      "[4,   901]  loss 0.076486 (0.138669) train_acc 96.875000 (95.766856)\n",
      "[5,     1]  loss 0.158908 (0.158908) train_acc 98.437500 (98.437500)\n",
      "[5,   101]  loss 0.165321 (0.122295) train_acc 93.750000 (96.101485)\n",
      "[5,   201]  loss 0.040388 (0.118901) train_acc 100.000000 (96.237562)\n",
      "[5,   301]  loss 0.083081 (0.117056) train_acc 95.312500 (96.324751)\n",
      "[5,   401]  loss 0.122480 (0.114456) train_acc 95.312500 (96.387936)\n",
      "[5,   501]  loss 0.154382 (0.116622) train_acc 96.875000 (96.335454)\n",
      "[5,   601]  loss 0.030741 (0.114261) train_acc 100.000000 (96.373232)\n",
      "[5,   701]  loss 0.193785 (0.113008) train_acc 95.312500 (96.404690)\n",
      "[5,   801]  loss 0.099622 (0.113232) train_acc 98.437500 (96.420490)\n",
      "[5,   901]  loss 0.180838 (0.111330) train_acc 96.875000 (96.510821)\n",
      "[6,     1]  loss 0.096255 (0.096255) train_acc 96.875000 (96.875000)\n",
      "[6,   101]  loss 0.037286 (0.096882) train_acc 100.000000 (97.091584)\n",
      "[6,   201]  loss 0.114467 (0.097017) train_acc 95.312500 (97.092662)\n",
      "[6,   301]  loss 0.041390 (0.097172) train_acc 100.000000 (97.087832)\n",
      "[6,   401]  loss 0.092946 (0.095677) train_acc 96.875000 (97.073722)\n",
      "[6,   501]  loss 0.066504 (0.095935) train_acc 96.875000 (97.062126)\n",
      "[6,   601]  loss 0.048182 (0.094612) train_acc 98.437500 (97.054389)\n",
      "[6,   701]  loss 0.149585 (0.094041) train_acc 93.750000 (97.071148)\n",
      "[6,   801]  loss 0.084141 (0.094342) train_acc 98.437500 (97.073970)\n",
      "[6,   901]  loss 0.137675 (0.093221) train_acc 95.312500 (97.103912)\n",
      "[7,     1]  loss 0.040867 (0.040867) train_acc 100.000000 (100.000000)\n",
      "[7,   101]  loss 0.059923 (0.080829) train_acc 100.000000 (97.431931)\n",
      "[7,   201]  loss 0.090862 (0.082918) train_acc 96.875000 (97.411381)\n",
      "[7,   301]  loss 0.020363 (0.082416) train_acc 100.000000 (97.451204)\n",
      "[7,   401]  loss 0.112513 (0.082674) train_acc 96.875000 (97.432201)\n",
      "[7,   501]  loss 0.143095 (0.082760) train_acc 93.750000 (97.405190)\n",
      "[7,   601]  loss 0.082566 (0.083317) train_acc 96.875000 (97.387167)\n",
      "[7,   701]  loss 0.080837 (0.082353) train_acc 96.875000 (97.434469)\n",
      "[7,   801]  loss 0.126151 (0.082224) train_acc 95.312500 (97.444600)\n",
      "[7,   901]  loss 0.033324 (0.081894) train_acc 100.000000 (97.445547)\n",
      "[8,     1]  loss 0.049152 (0.049152) train_acc 98.437500 (98.437500)\n",
      "[8,   101]  loss 0.058147 (0.077584) train_acc 96.875000 (97.787748)\n",
      "[8,   201]  loss 0.077080 (0.079058) train_acc 95.312500 (97.675684)\n",
      "[8,   301]  loss 0.035554 (0.076564) train_acc 100.000000 (97.664037)\n",
      "[8,   401]  loss 0.021778 (0.076945) train_acc 100.000000 (97.697163)\n",
      "[8,   501]  loss 0.044351 (0.076144) train_acc 98.437500 (97.742016)\n",
      "[8,   601]  loss 0.080127 (0.075316) train_acc 95.312500 (97.725146)\n",
      "[8,   701]  loss 0.097825 (0.074780) train_acc 96.875000 (97.730920)\n",
      "[8,   801]  loss 0.318170 (0.074106) train_acc 92.187500 (97.745006)\n",
      "[8,   901]  loss 0.054745 (0.073803) train_acc 98.437500 (97.750763)\n",
      "[9,     1]  loss 0.067101 (0.067101) train_acc 96.875000 (96.875000)\n",
      "[9,   101]  loss 0.018497 (0.070153) train_acc 100.000000 (97.911510)\n",
      "[9,   201]  loss 0.114865 (0.070805) train_acc 96.875000 (97.908893)\n",
      "[9,   301]  loss 0.026852 (0.068819) train_acc 100.000000 (97.933970)\n",
      "[9,   401]  loss 0.068291 (0.069262) train_acc 96.875000 (97.868610)\n",
      "[9,   501]  loss 0.054929 (0.068544) train_acc 96.875000 (97.876123)\n",
      "[9,   601]  loss 0.180452 (0.069495) train_acc 96.875000 (97.808340)\n",
      "[9,   701]  loss 0.022595 (0.069164) train_acc 100.000000 (97.840139)\n",
      "[9,   801]  loss 0.106580 (0.067920) train_acc 95.312500 (97.877653)\n",
      "[9,   901]  loss 0.039869 (0.067612) train_acc 100.000000 (97.899903)\n",
      "[10,     1]  loss 0.053966 (0.053966) train_acc 96.875000 (96.875000)\n",
      "[10,   101]  loss 0.026890 (0.066296) train_acc 100.000000 (97.849629)\n",
      "[10,   201]  loss 0.049044 (0.068337) train_acc 96.875000 (97.870025)\n",
      "[10,   301]  loss 0.016005 (0.067061) train_acc 100.000000 (97.954734)\n",
      "[10,   401]  loss 0.129266 (0.067197) train_acc 96.875000 (97.969919)\n",
      "[10,   501]  loss 0.083192 (0.066318) train_acc 98.437500 (98.025823)\n",
      "[10,   601]  loss 0.107047 (0.065577) train_acc 98.437500 (98.047525)\n",
      "[10,   701]  loss 0.036763 (0.063300) train_acc 98.437500 (98.114301)\n",
      "[10,   801]  loss 0.027387 (0.062057) train_acc 100.000000 (98.168305)\n",
      "[10,   901]  loss 0.049418 (0.062473) train_acc 98.437500 (98.144423)\n",
      "[11,     1]  loss 0.070499 (0.070499) train_acc 96.875000 (96.875000)\n",
      "[11,   101]  loss 0.086635 (0.052497) train_acc 98.437500 (98.375619)\n",
      "[11,   201]  loss 0.076908 (0.055097) train_acc 96.875000 (98.383085)\n",
      "[11,   301]  loss 0.040561 (0.056138) train_acc 98.437500 (98.354444)\n",
      "[11,   401]  loss 0.028053 (0.058057) train_acc 98.437500 (98.269950)\n",
      "[11,   501]  loss 0.066289 (0.058843) train_acc 96.875000 (98.212949)\n",
      "[11,   601]  loss 0.048829 (0.058581) train_acc 96.875000 (98.174917)\n",
      "[11,   701]  loss 0.063659 (0.058231) train_acc 96.875000 (98.199001)\n",
      "[11,   801]  loss 0.016936 (0.058240) train_acc 100.000000 (98.172207)\n",
      "[11,   901]  loss 0.045557 (0.058769) train_acc 98.437500 (98.172170)\n",
      "[12,     1]  loss 0.113326 (0.113326) train_acc 95.312500 (95.312500)\n",
      "[12,   101]  loss 0.020728 (0.056975) train_acc 100.000000 (98.344678)\n",
      "[12,   201]  loss 0.013770 (0.058915) train_acc 100.000000 (98.196517)\n",
      "[12,   301]  loss 0.007128 (0.059475) train_acc 100.000000 (98.250623)\n",
      "[12,   401]  loss 0.056633 (0.059620) train_acc 96.875000 (98.234882)\n",
      "[12,   501]  loss 0.007970 (0.058118) train_acc 100.000000 (98.262849)\n",
      "[12,   601]  loss 0.034160 (0.056678) train_acc 98.437500 (98.286710)\n",
      "[12,   701]  loss 0.033627 (0.055876) train_acc 100.000000 (98.290389)\n",
      "[12,   801]  loss 0.077084 (0.054945) train_acc 96.875000 (98.318508)\n",
      "[12,   901]  loss 0.021960 (0.054682) train_acc 100.000000 (98.323044)\n",
      "[13,     1]  loss 0.023398 (0.023398) train_acc 100.000000 (100.000000)\n",
      "[13,   101]  loss 0.049767 (0.046647) train_acc 98.437500 (98.545792)\n",
      "[13,   201]  loss 0.118299 (0.047761) train_acc 98.437500 (98.600746)\n",
      "[13,   301]  loss 0.104815 (0.048878) train_acc 98.437500 (98.530939)\n",
      "[13,   401]  loss 0.067696 (0.050465) train_acc 96.875000 (98.445293)\n",
      "[13,   501]  loss 0.018407 (0.051531) train_acc 100.000000 (98.449975)\n",
      "[13,   601]  loss 0.054510 (0.050348) train_acc 100.000000 (98.484297)\n",
      "[13,   701]  loss 0.023517 (0.051104) train_acc 100.000000 (98.477621)\n",
      "[13,   801]  loss 0.041520 (0.051850) train_acc 98.437500 (98.460908)\n",
      "[13,   901]  loss 0.012935 (0.051356) train_acc 100.000000 (98.463513)\n",
      "[14,     1]  loss 0.036317 (0.036317) train_acc 98.437500 (98.437500)\n",
      "[14,   101]  loss 0.031441 (0.047975) train_acc 98.437500 (98.437500)\n",
      "[14,   201]  loss 0.114700 (0.045676) train_acc 98.437500 (98.546331)\n",
      "[14,   301]  loss 0.086560 (0.045979) train_acc 96.875000 (98.473837)\n",
      "[14,   401]  loss 0.069019 (0.044856) train_acc 98.437500 (98.531016)\n",
      "[14,   501]  loss 0.033835 (0.045980) train_acc 98.437500 (98.496756)\n",
      "[14,   601]  loss 0.013890 (0.046286) train_acc 100.000000 (98.502496)\n",
      "[14,   701]  loss 0.050725 (0.046932) train_acc 98.437500 (98.508827)\n",
      "[14,   801]  loss 0.016666 (0.048244) train_acc 100.000000 (98.468711)\n",
      "[14,   901]  loss 0.013719 (0.048423) train_acc 100.000000 (98.454842)\n",
      "[15,     1]  loss 0.020021 (0.020021) train_acc 100.000000 (100.000000)\n",
      "[15,   101]  loss 0.043065 (0.049796) train_acc 96.875000 (98.561262)\n",
      "[15,   201]  loss 0.056760 (0.046205) train_acc 98.437500 (98.608520)\n",
      "[15,   301]  loss 0.068901 (0.045580) train_acc 98.437500 (98.608804)\n",
      "[15,   401]  loss 0.006265 (0.046905) train_acc 100.000000 (98.589464)\n",
      "[15,   501]  loss 0.016610 (0.047309) train_acc 100.000000 (98.552894)\n",
      "[15,   601]  loss 0.025652 (0.047326) train_acc 98.437500 (98.554493)\n",
      "[15,   701]  loss 0.045019 (0.047553) train_acc 96.875000 (98.555635)\n",
      "[15,   801]  loss 0.055784 (0.046105) train_acc 98.437500 (98.589654)\n",
      "[15,   901]  loss 0.019967 (0.045370) train_acc 100.000000 (98.607450)\n",
      "[16,     1]  loss 0.087837 (0.087837) train_acc 96.875000 (96.875000)\n",
      "[16,   101]  loss 0.079184 (0.043326) train_acc 96.875000 (98.731436)\n",
      "[16,   201]  loss 0.062912 (0.040945) train_acc 98.437500 (98.771766)\n",
      "[16,   301]  loss 0.052071 (0.042297) train_acc 98.437500 (98.676287)\n",
      "[16,   401]  loss 0.036601 (0.043784) train_acc 98.437500 (98.636222)\n",
      "[16,   501]  loss 0.031027 (0.044305) train_acc 98.437500 (98.627745)\n",
      "[16,   601]  loss 0.038479 (0.043566) train_acc 98.437500 (98.661086)\n",
      "[16,   701]  loss 0.012457 (0.043634) train_acc 100.000000 (98.669312)\n",
      "[16,   801]  loss 0.008961 (0.043533) train_acc 100.000000 (98.671582)\n",
      "[16,   901]  loss 0.025494 (0.043314) train_acc 100.000000 (98.683754)\n",
      "[17,     1]  loss 0.037948 (0.037948) train_acc 98.437500 (98.437500)\n",
      "[17,   101]  loss 0.026027 (0.032433) train_acc 98.437500 (98.932550)\n",
      "[17,   201]  loss 0.005463 (0.033374) train_acc 100.000000 (98.966107)\n",
      "[17,   301]  loss 0.014889 (0.036833) train_acc 100.000000 (98.816445)\n",
      "[17,   401]  loss 0.007374 (0.039737) train_acc 100.000000 (98.749221)\n",
      "[17,   501]  loss 0.114485 (0.041231) train_acc 98.437500 (98.727545)\n",
      "[17,   601]  loss 0.016181 (0.040670) train_acc 100.000000 (98.770279)\n",
      "[17,   701]  loss 0.031158 (0.040607) train_acc 98.437500 (98.760699)\n",
      "[17,   801]  loss 0.009119 (0.040887) train_acc 100.000000 (98.755462)\n",
      "[17,   901]  loss 0.024613 (0.041222) train_acc 98.437500 (98.732311)\n",
      "[18,     1]  loss 0.013073 (0.013073) train_acc 100.000000 (100.000000)\n",
      "[18,   101]  loss 0.011966 (0.036029) train_acc 100.000000 (98.963490)\n",
      "[18,   201]  loss 0.045243 (0.036377) train_acc 96.875000 (98.919465)\n",
      "[18,   301]  loss 0.010833 (0.035889) train_acc 100.000000 (98.935839)\n",
      "[18,   401]  loss 0.027143 (0.036513) train_acc 98.437500 (98.901185)\n",
      "[18,   501]  loss 0.056430 (0.037956) train_acc 95.312500 (98.858533)\n",
      "[18,   601]  loss 0.090911 (0.038711) train_acc 98.437500 (98.832675)\n",
      "[18,   701]  loss 0.002199 (0.039042) train_acc 100.000000 (98.820881)\n",
      "[18,   801]  loss 0.160073 (0.038851) train_acc 96.875000 (98.815933)\n",
      "[18,   901]  loss 0.072777 (0.038669) train_acc 98.437500 (98.810350)\n",
      "[19,     1]  loss 0.014348 (0.014348) train_acc 100.000000 (100.000000)\n",
      "[19,   101]  loss 0.032857 (0.037561) train_acc 96.875000 (98.746906)\n",
      "[19,   201]  loss 0.076032 (0.036002) train_acc 98.437500 (98.826182)\n",
      "[19,   301]  loss 0.071585 (0.036905) train_acc 96.875000 (98.826827)\n",
      "[19,   401]  loss 0.008678 (0.036871) train_acc 100.000000 (98.819358)\n",
      "[19,   501]  loss 0.011286 (0.036495) train_acc 100.000000 (98.861652)\n",
      "[19,   601]  loss 0.020858 (0.036528) train_acc 98.437500 (98.866473)\n",
      "[19,   701]  loss 0.008820 (0.036708) train_acc 100.000000 (98.838713)\n",
      "[19,   801]  loss 0.030832 (0.036273) train_acc 98.437500 (98.851046)\n",
      "[19,   901]  loss 0.003553 (0.036824) train_acc 100.000000 (98.834628)\n",
      "[20,     1]  loss 0.044058 (0.044058) train_acc 98.437500 (98.437500)\n",
      "[20,   101]  loss 0.068198 (0.042208) train_acc 98.437500 (98.746906)\n",
      "[20,   201]  loss 0.006362 (0.035734) train_acc 100.000000 (98.950560)\n",
      "[20,   301]  loss 0.030038 (0.035410) train_acc 98.437500 (98.930648)\n",
      "[20,   401]  loss 0.201898 (0.036095) train_acc 95.312500 (98.924564)\n",
      "[20,   501]  loss 0.013852 (0.035945) train_acc 100.000000 (98.917789)\n",
      "[20,   601]  loss 0.077302 (0.036439) train_acc 96.875000 (98.900270)\n",
      "[20,   701]  loss 0.021593 (0.036630) train_acc 98.437500 (98.889979)\n",
      "[20,   801]  loss 0.023490 (0.036263) train_acc 100.000000 (98.899813)\n",
      "[20,   901]  loss 0.007379 (0.035823) train_acc 100.000000 (98.897059)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(qnet, trainloader, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "vKoPoXnPuxWR",
    "outputId": "24e85c70-aab2-45a0-d8c2-3a2bea53c95c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model after quantization\n",
      "Size (MB): 0.05572\n",
      "Accuracy of the fused and quantized network (trained quantized) on the test images: 98.64% - INT8\n"
     ]
    }
   ],
   "source": [
    "qnet = qnet.cpu()\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)\n",
    "\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network (trained quantized) on the test images: {}% - INT8'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcHE8SBitv9W"
   },
   "source": [
    "Обучение квантованной модели с высокой точностью требует точного моделирования чисел при выводе. Поэтому для обучения с учетом квантования мы можем изменить цикл обучения, заморозив параметры квантизатора (масштаб и нулевая точка) и точно настроить веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1OvCOpSFvIJt",
    "outputId": "d6aaaf2e-46e5-441b-97c7-0293d2a479be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1]  loss 2.302550 (2.302550) train_acc 7.812500 (7.812500)\n",
      "[1,   101]  loss 2.297554 (2.300715) train_acc 20.312500 (13.845916)\n",
      "[1,   201]  loss 2.282641 (2.297055) train_acc 34.375000 (18.135883)\n",
      "[1,   301]  loss 2.270876 (2.292123) train_acc 39.062500 (22.809385)\n",
      "[1,   401]  loss 2.262033 (2.285715) train_acc 37.500000 (26.683292)\n",
      "[1,   501]  loss 2.202892 (2.275584) train_acc 53.125000 (30.417290)\n",
      "[1,   601]  loss 2.071962 (2.256968) train_acc 45.312500 (33.236273)\n",
      "[1,   701]  loss 1.763640 (2.214525) train_acc 59.375000 (35.529601)\n",
      "[1,   801]  loss 1.114516 (2.123895) train_acc 76.562500 (39.054697)\n",
      "[1,   901]  loss 0.700801 (1.992948) train_acc 85.937500 (43.215871)\n",
      "[2,     1]  loss 0.738226 (0.738226) train_acc 84.375000 (84.375000)\n",
      "[2,   101]  loss 0.517096 (0.564659) train_acc 85.937500 (84.730817)\n",
      "[2,   201]  loss 0.456042 (0.522940) train_acc 87.500000 (85.432214)\n",
      "[2,   301]  loss 0.316576 (0.485950) train_acc 89.062500 (86.399502)\n",
      "[2,   401]  loss 0.328412 (0.451746) train_acc 93.750000 (87.375312)\n",
      "[2,   501]  loss 0.150412 (0.423844) train_acc 98.437500 (88.045783)\n",
      "[2,   601]  loss 0.179842 (0.400242) train_acc 93.750000 (88.649126)\n",
      "[2,   701]  loss 0.228518 (0.383382) train_acc 92.187500 (89.042439)\n",
      "[2,   801]  loss 0.474089 (0.366581) train_acc 85.937500 (89.493602)\n",
      "[2,   901]  loss 0.137446 (0.352672) train_acc 93.750000 (89.820339)\n",
      "[3,     1]  loss 0.157492 (0.157492) train_acc 95.312500 (95.312500)\n",
      "[3,   101]  loss 0.191074 (0.214266) train_acc 93.750000 (93.641708)\n",
      "[3,   201]  loss 0.286669 (0.212748) train_acc 89.062500 (93.547886)\n",
      "[3,   301]  loss 0.118892 (0.206445) train_acc 96.875000 (93.781146)\n",
      "[3,   401]  loss 0.155797 (0.203225) train_acc 95.312500 (93.812344)\n",
      "[3,   501]  loss 0.220620 (0.199711) train_acc 93.750000 (93.902819)\n",
      "[3,   601]  loss 0.103094 (0.198659) train_acc 96.875000 (93.944988)\n",
      "[3,   701]  loss 0.128453 (0.193869) train_acc 96.875000 (94.068741)\n",
      "[3,   801]  loss 0.313520 (0.191558) train_acc 90.625000 (94.163546)\n",
      "[3,   901]  loss 0.275842 (0.189198) train_acc 95.312500 (94.251179)\n",
      "[4,     1]  loss 0.120804 (0.120804) train_acc 95.312500 (95.312500)\n",
      "[4,   101]  loss 0.112875 (0.151322) train_acc 98.437500 (95.745668)\n",
      "[4,   201]  loss 0.098576 (0.148086) train_acc 96.875000 (95.708955)\n",
      "[4,   301]  loss 0.267649 (0.147990) train_acc 93.750000 (95.639535)\n",
      "[4,   401]  loss 0.125630 (0.146719) train_acc 93.750000 (95.647600)\n",
      "[4,   501]  loss 0.094601 (0.144580) train_acc 96.875000 (95.683633)\n",
      "[4,   601]  loss 0.159038 (0.142246) train_acc 95.312500 (95.736273)\n",
      "[4,   701]  loss 0.090629 (0.140874) train_acc 95.312500 (95.773894)\n",
      "[4,   801]  loss 0.094944 (0.140627) train_acc 98.437500 (95.774813)\n",
      "[4,   901]  loss 0.066600 (0.139774) train_acc 98.437500 (95.778996)\n",
      "[5,     1]  loss 0.083039 (0.083039) train_acc 96.875000 (96.875000)\n",
      "[5,   101]  loss 0.105796 (0.128018) train_acc 96.875000 (96.147896)\n",
      "[5,   201]  loss 0.136708 (0.124957) train_acc 95.312500 (96.105410)\n",
      "[5,   301]  loss 0.180986 (0.124585) train_acc 96.875000 (96.137874)\n",
      "[5,   401]  loss 0.228525 (0.120904) train_acc 90.625000 (96.290524)\n",
      "[5,   501]  loss 0.157131 (0.119609) train_acc 95.312500 (96.344810)\n",
      "[5,   601]  loss 0.147801 (0.120152) train_acc 93.750000 (96.339434)\n",
      "[5,   701]  loss 0.092475 (0.119133) train_acc 95.312500 (96.398003)\n",
      "[5,   801]  loss 0.030053 (0.117845) train_acc 100.000000 (96.445849)\n",
      "[5,   901]  loss 0.057119 (0.116151) train_acc 98.437500 (96.509087)\n",
      "[6,     1]  loss 0.065908 (0.065908) train_acc 96.875000 (96.875000)\n",
      "[6,   101]  loss 0.178128 (0.102600) train_acc 95.312500 (96.859530)\n",
      "[6,   201]  loss 0.106632 (0.103455) train_acc 93.750000 (96.735075)\n",
      "[6,   301]  loss 0.149924 (0.104807) train_acc 95.312500 (96.688123)\n",
      "[6,   401]  loss 0.201291 (0.104085) train_acc 93.750000 (96.765898)\n",
      "[6,   501]  loss 0.044459 (0.103514) train_acc 100.000000 (96.765843)\n",
      "[6,   601]  loss 0.103602 (0.104020) train_acc 98.437500 (96.752808)\n",
      "[6,   701]  loss 0.050781 (0.103043) train_acc 96.875000 (96.785842)\n",
      "[6,   801]  loss 0.092638 (0.101568) train_acc 96.875000 (96.828184)\n",
      "[6,   901]  loss 0.121193 (0.101234) train_acc 93.750000 (96.821240)\n",
      "[7,     1]  loss 0.027914 (0.027914) train_acc 100.000000 (100.000000)\n",
      "[7,   101]  loss 0.085401 (0.105230) train_acc 98.437500 (96.612005)\n",
      "[7,   201]  loss 0.036594 (0.095268) train_acc 100.000000 (97.022699)\n",
      "[7,   301]  loss 0.076280 (0.097793) train_acc 98.437500 (97.015158)\n",
      "[7,   401]  loss 0.043487 (0.095206) train_acc 98.437500 (97.100998)\n",
      "[7,   501]  loss 0.024349 (0.095355) train_acc 100.000000 (97.099551)\n",
      "[7,   601]  loss 0.162680 (0.095196) train_acc 96.875000 (97.103785)\n",
      "[7,   701]  loss 0.061703 (0.093244) train_acc 98.437500 (97.133559)\n",
      "[7,   801]  loss 0.074943 (0.092670) train_acc 96.875000 (97.151998)\n",
      "[7,   901]  loss 0.060584 (0.091453) train_acc 98.437500 (97.192356)\n",
      "[8,     1]  loss 0.152832 (0.152832) train_acc 95.312500 (95.312500)\n",
      "[8,   101]  loss 0.035814 (0.086930) train_acc 98.437500 (97.354579)\n",
      "[8,   201]  loss 0.102473 (0.089991) train_acc 93.750000 (97.201493)\n",
      "[8,   301]  loss 0.141122 (0.085625) train_acc 93.750000 (97.285091)\n",
      "[8,   401]  loss 0.084509 (0.085933) train_acc 96.875000 (97.295823)\n",
      "[8,   501]  loss 0.046042 (0.084555) train_acc 98.437500 (97.339696)\n",
      "[8,   601]  loss 0.144402 (0.084298) train_acc 96.875000 (97.379368)\n",
      "[8,   701]  loss 0.063557 (0.084965) train_acc 96.875000 (97.354226)\n",
      "[8,   801]  loss 0.034335 (0.083684) train_acc 98.437500 (97.384129)\n",
      "[8,   901]  loss 0.135376 (0.083938) train_acc 96.875000 (97.388319)\n",
      "[9,     1]  loss 0.080674 (0.080674) train_acc 95.312500 (95.312500)\n",
      "[9,   101]  loss 0.080960 (0.079276) train_acc 96.875000 (97.447401)\n",
      "[9,   201]  loss 0.039168 (0.082197) train_acc 100.000000 (97.465796)\n",
      "[9,   301]  loss 0.040251 (0.079286) train_acc 100.000000 (97.477159)\n",
      "[9,   401]  loss 0.080177 (0.078448) train_acc 96.875000 (97.564682)\n",
      "[9,   501]  loss 0.137624 (0.078713) train_acc 93.750000 (97.548653)\n",
      "[9,   601]  loss 0.048188 (0.078182) train_acc 98.437500 (97.592554)\n",
      "[9,   701]  loss 0.152732 (0.079140) train_acc 92.187500 (97.572664)\n",
      "[9,   801]  loss 0.076186 (0.078587) train_acc 98.437500 (97.598705)\n",
      "[9,   901]  loss 0.081240 (0.078819) train_acc 96.875000 (97.596421)\n",
      "[10,     1]  loss 0.036151 (0.036151) train_acc 98.437500 (98.437500)\n",
      "[10,   101]  loss 0.065628 (0.070995) train_acc 98.437500 (97.818688)\n",
      "[10,   201]  loss 0.081905 (0.072232) train_acc 95.312500 (97.854478)\n",
      "[10,   301]  loss 0.036074 (0.071981) train_acc 98.437500 (97.840532)\n",
      "[10,   401]  loss 0.050633 (0.074849) train_acc 98.437500 (97.747818)\n",
      "[10,   501]  loss 0.038039 (0.074749) train_acc 98.437500 (97.735778)\n",
      "[10,   601]  loss 0.092357 (0.076482) train_acc 96.875000 (97.665349)\n",
      "[10,   701]  loss 0.024741 (0.074530) train_acc 100.000000 (97.737607)\n",
      "[10,   801]  loss 0.015401 (0.073452) train_acc 100.000000 (97.787921)\n",
      "[10,   901]  loss 0.013214 (0.073495) train_acc 100.000000 (97.809725)\n",
      "[11,     1]  loss 0.021667 (0.021667) train_acc 98.437500 (98.437500)\n",
      "[11,   101]  loss 0.037800 (0.078155) train_acc 98.437500 (97.586634)\n",
      "[11,   201]  loss 0.049924 (0.070107) train_acc 98.437500 (97.846704)\n",
      "[11,   301]  loss 0.070509 (0.071629) train_acc 98.437500 (97.788621)\n",
      "[11,   401]  loss 0.087520 (0.070533) train_acc 96.875000 (97.786783)\n",
      "[11,   501]  loss 0.115143 (0.069339) train_acc 96.875000 (97.816866)\n",
      "[11,   601]  loss 0.067641 (0.069719) train_acc 96.875000 (97.805740)\n",
      "[11,   701]  loss 0.133686 (0.069835) train_acc 95.312500 (97.824536)\n",
      "[11,   801]  loss 0.019427 (0.069404) train_acc 100.000000 (97.840590)\n",
      "[11,   901]  loss 0.182608 (0.069460) train_acc 93.750000 (97.830536)\n",
      "[12,     1]  loss 0.013651 (0.013651) train_acc 100.000000 (100.000000)\n",
      "[12,   101]  loss 0.084725 (0.060728) train_acc 95.312500 (98.174505)\n",
      "[12,   201]  loss 0.107834 (0.066546) train_acc 95.312500 (98.002177)\n",
      "[12,   301]  loss 0.064416 (0.064022) train_acc 98.437500 (98.105274)\n",
      "[12,   401]  loss 0.102449 (0.064468) train_acc 96.875000 (98.114090)\n",
      "[12,   501]  loss 0.228205 (0.066359) train_acc 93.750000 (98.047655)\n",
      "[12,   601]  loss 0.029645 (0.065243) train_acc 100.000000 (98.068324)\n",
      "[12,   701]  loss 0.052124 (0.065814) train_acc 98.437500 (98.018456)\n",
      "[12,   801]  loss 0.156821 (0.065505) train_acc 96.875000 (98.033708)\n",
      "[12,   901]  loss 0.028394 (0.065984) train_acc 98.437500 (98.003954)\n",
      "[13,     1]  loss 0.119072 (0.119072) train_acc 96.875000 (96.875000)\n",
      "[13,   101]  loss 0.050072 (0.054741) train_acc 98.437500 (98.422030)\n",
      "[13,   201]  loss 0.067381 (0.060345) train_acc 98.437500 (98.180970)\n",
      "[13,   301]  loss 0.048072 (0.060722) train_acc 96.875000 (98.183140)\n",
      "[13,   401]  loss 0.186138 (0.061943) train_acc 96.875000 (98.129676)\n",
      "[13,   501]  loss 0.027444 (0.064065) train_acc 98.437500 (98.075724)\n",
      "[13,   601]  loss 0.047273 (0.062451) train_acc 96.875000 (98.094322)\n",
      "[13,   701]  loss 0.057710 (0.062872) train_acc 96.875000 (98.076409)\n",
      "[13,   801]  loss 0.060320 (0.063511) train_acc 96.875000 (98.076623)\n",
      "[13,   901]  loss 0.037433 (0.063473) train_acc 98.437500 (98.061182)\n",
      "[14,     1]  loss 0.038703 (0.038703) train_acc 100.000000 (100.000000)\n",
      "[14,   101]  loss 0.021609 (0.053827) train_acc 100.000000 (98.391089)\n",
      "[14,   201]  loss 0.058564 (0.056649) train_acc 98.437500 (98.266480)\n",
      "[14,   301]  loss 0.037816 (0.057818) train_acc 98.437500 (98.203904)\n",
      "[14,   401]  loss 0.067520 (0.059272) train_acc 98.437500 (98.211502)\n",
      "[14,   501]  loss 0.019934 (0.060878) train_acc 100.000000 (98.116267)\n",
      "[14,   601]  loss 0.035314 (0.060599) train_acc 98.437500 (98.146319)\n",
      "[14,   701]  loss 0.124766 (0.061728) train_acc 98.437500 (98.096469)\n",
      "[14,   801]  loss 0.040369 (0.061778) train_acc 98.437500 (98.098081)\n",
      "[14,   901]  loss 0.010305 (0.060288) train_acc 100.000000 (98.154828)\n",
      "[15,     1]  loss 0.022719 (0.022719) train_acc 98.437500 (98.437500)\n",
      "[15,   101]  loss 0.263579 (0.057640) train_acc 92.187500 (98.313738)\n",
      "[15,   201]  loss 0.030529 (0.058956) train_acc 98.437500 (98.219838)\n",
      "[15,   301]  loss 0.064915 (0.058186) train_acc 98.437500 (98.229859)\n",
      "[15,   401]  loss 0.011687 (0.056681) train_acc 100.000000 (98.308915)\n",
      "[15,   501]  loss 0.140703 (0.056459) train_acc 96.875000 (98.309631)\n",
      "[15,   601]  loss 0.142636 (0.057355) train_acc 95.312500 (98.291909)\n",
      "[15,   701]  loss 0.024441 (0.057568) train_acc 98.437500 (98.268099)\n",
      "[15,   801]  loss 0.080110 (0.057504) train_acc 95.312500 (98.248283)\n",
      "[15,   901]  loss 0.058720 (0.057768) train_acc 98.437500 (98.245006)\n",
      "[16,     1]  loss 0.011128 (0.011128) train_acc 100.000000 (100.000000)\n",
      "[16,   101]  loss 0.026723 (0.057070) train_acc 100.000000 (98.128094)\n",
      "[16,   201]  loss 0.051001 (0.051976) train_acc 96.875000 (98.336443)\n",
      "[16,   301]  loss 0.031592 (0.053245) train_acc 100.000000 (98.328488)\n",
      "[16,   401]  loss 0.098772 (0.053506) train_acc 96.875000 (98.332294)\n",
      "[16,   501]  loss 0.141219 (0.054016) train_acc 96.875000 (98.328343)\n",
      "[16,   601]  loss 0.058870 (0.053847) train_acc 98.437500 (98.354305)\n",
      "[16,   701]  loss 0.007093 (0.053943) train_acc 100.000000 (98.350571)\n",
      "[16,   801]  loss 0.132708 (0.054902) train_acc 96.875000 (98.332163)\n",
      "[16,   901]  loss 0.037177 (0.055351) train_acc 98.437500 (98.324778)\n",
      "[17,     1]  loss 0.005327 (0.005327) train_acc 100.000000 (100.000000)\n",
      "[17,   101]  loss 0.077196 (0.053524) train_acc 98.437500 (98.530322)\n",
      "[17,   201]  loss 0.021868 (0.054216) train_acc 100.000000 (98.445274)\n",
      "[17,   301]  loss 0.011024 (0.055832) train_acc 100.000000 (98.333679)\n",
      "[17,   401]  loss 0.027054 (0.055034) train_acc 98.437500 (98.332294)\n",
      "[17,   501]  loss 0.010150 (0.054225) train_acc 100.000000 (98.337700)\n",
      "[17,   601]  loss 0.029712 (0.054110) train_acc 98.437500 (98.349106)\n",
      "[17,   701]  loss 0.035342 (0.054022) train_acc 98.437500 (98.352800)\n",
      "[17,   801]  loss 0.059302 (0.053984) train_acc 96.875000 (98.343867)\n",
      "[17,   901]  loss 0.068517 (0.053667) train_acc 98.437500 (98.342120)\n",
      "[18,     1]  loss 0.075476 (0.075476) train_acc 98.437500 (98.437500)\n",
      "[18,   101]  loss 0.145757 (0.052178) train_acc 96.875000 (98.329208)\n",
      "[18,   201]  loss 0.043926 (0.053253) train_acc 98.437500 (98.359764)\n",
      "[18,   301]  loss 0.049170 (0.053832) train_acc 98.437500 (98.375208)\n",
      "[18,   401]  loss 0.036931 (0.053273) train_acc 98.437500 (98.359570)\n",
      "[18,   501]  loss 0.019969 (0.053371) train_acc 100.000000 (98.381362)\n",
      "[18,   601]  loss 0.038306 (0.053556) train_acc 98.437500 (98.372504)\n",
      "[18,   701]  loss 0.041648 (0.052409) train_acc 100.000000 (98.417439)\n",
      "[18,   801]  loss 0.024367 (0.051907) train_acc 98.437500 (98.431648)\n",
      "[18,   901]  loss 0.028199 (0.051279) train_acc 98.437500 (98.449639)\n",
      "[19,     1]  loss 0.077943 (0.077943) train_acc 98.437500 (98.437500)\n",
      "[19,   101]  loss 0.041550 (0.052222) train_acc 98.437500 (98.205446)\n",
      "[19,   201]  loss 0.050326 (0.046886) train_acc 96.875000 (98.445274)\n",
      "[19,   301]  loss 0.012051 (0.047147) train_acc 100.000000 (98.494601)\n",
      "[19,   401]  loss 0.034183 (0.049236) train_acc 98.437500 (98.476465)\n",
      "[19,   501]  loss 0.020020 (0.048748) train_acc 100.000000 (98.506113)\n",
      "[19,   601]  loss 0.141519 (0.048220) train_acc 95.312500 (98.525894)\n",
      "[19,   701]  loss 0.032047 (0.049645) train_acc 100.000000 (98.495453)\n",
      "[19,   801]  loss 0.082106 (0.049142) train_acc 96.875000 (98.505774)\n",
      "[19,   901]  loss 0.072608 (0.049163) train_acc 96.875000 (98.505133)\n",
      "[20,     1]  loss 0.042147 (0.042147) train_acc 100.000000 (100.000000)\n",
      "[20,   101]  loss 0.069253 (0.049164) train_acc 98.437500 (98.592203)\n",
      "[20,   201]  loss 0.066975 (0.049972) train_acc 98.437500 (98.561878)\n",
      "[20,   301]  loss 0.114514 (0.050178) train_acc 96.875000 (98.536130)\n",
      "[20,   401]  loss 0.014213 (0.048549) train_acc 100.000000 (98.554395)\n",
      "[20,   501]  loss 0.032720 (0.048352) train_acc 98.437500 (98.546657)\n",
      "[20,   601]  loss 0.129583 (0.048267) train_acc 96.875000 (98.538894)\n",
      "[20,   701]  loss 0.070022 (0.048461) train_acc 95.312500 (98.535574)\n",
      "[20,   801]  loss 0.007984 (0.048427) train_acc 100.000000 (98.540886)\n",
      "[20,   901]  loss 0.098393 (0.048538) train_acc 96.875000 (98.531146)\n",
      "Finished Training\n",
      "Size of model after quantization\n",
      "Size (MB): 0.056182\n",
      "Accuracy of the fused and quantized network (trained quantized) on the test images: 98.51% - INT8\n"
     ]
    }
   ],
   "source": [
    "qnet = Net(q=True)\n",
    "\n",
    "fuse_modules(qnet)\n",
    "\n",
    "qnet.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
    "torch.quantization.prepare_qat(qnet, inplace=True)\n",
    "qnet = qnet.cuda()\n",
    "\n",
    "\n",
    "train(qnet, trainloader, cuda=True, q=True)\n",
    "\n",
    "qnet = qnet.cpu()\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(qnet)\n",
    "\n",
    "score = test(qnet, testloader, cuda=False)\n",
    "print('Accuracy of the fused and quantized network (trained quantized) on the test images: {}% - INT8'.format(score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "093c877eaa43432eabc2aa71c7f2b587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24c95a6a11b449c0b4c698ce5bdda18b",
      "placeholder": "​",
      "style": "IPY_MODEL_1c08dece76594deea344614336c0991d",
      "value": " 8192/? [00:00&lt;00:00, 19092.15it/s]"
     }
    },
    "09c7204e26a44c95872da1e227c30315": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e65e31421f9b40d4a3c59f36622e3163",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31805a8fbfde40cc9867a3643e829a44",
      "value": 1
     }
    },
    "1c08dece76594deea344614336c0991d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d71085620904406b58384c3bb0b1edf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_502a360a8774499c8b9a950c34a684e5",
      "placeholder": "​",
      "style": "IPY_MODEL_485835aae0cf48feac7afade58a6a521",
      "value": " 9920512/? [00:19&lt;00:00, 1054429.46it/s]"
     }
    },
    "1fba5940cf064fa68317af9792da8c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24c95a6a11b449c0b4c698ce5bdda18b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31805a8fbfde40cc9867a3643e829a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3c122842f89b418cbf2133d83e5ff48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f37affbd69e486dad7cddeb8c8c9cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4722aa0e04264c76964d58b5e3a65a32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4725f0f119e04f81a780a2489a8ef8dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "485835aae0cf48feac7afade58a6a521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ef3ac3a55b1405cbbfb495d511f8c57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09c7204e26a44c95872da1e227c30315",
       "IPY_MODEL_1d71085620904406b58384c3bb0b1edf"
      ],
      "layout": "IPY_MODEL_63735be95ec2408abd58846e255a7547"
     }
    },
    "502a360a8774499c8b9a950c34a684e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5840df2790f24f2c9c8d4d8427a2922b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "63735be95ec2408abd58846e255a7547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777a4203229d4a00b9dbf1e7603e0d36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c122842f89b418cbf2133d83e5ff48e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5840df2790f24f2c9c8d4d8427a2922b",
      "value": 1
     }
    },
    "84107f986d5b45bfb4d9a9c9f934d1de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88accd52e8fe4ccd8907edf082b47d97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90a2ffa504ff42329da39e7c1497c888": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1653abe0c694d5d8676a4c09bfe5800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88accd52e8fe4ccd8907edf082b47d97",
      "placeholder": "​",
      "style": "IPY_MODEL_1fba5940cf064fa68317af9792da8c3b",
      "value": " 32768/? [00:00&lt;00:00, 112823.38it/s]"
     }
    },
    "a4a8ee6bf1da4549a0e1fcfdba392b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_777a4203229d4a00b9dbf1e7603e0d36",
       "IPY_MODEL_093c877eaa43432eabc2aa71c7f2b587"
      ],
      "layout": "IPY_MODEL_aaf6e3a398a84014ad173b40d54a1a45"
     }
    },
    "a5171886b4bc4c67b758ce052c1cee77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaf6e3a398a84014ad173b40d54a1a45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18f211b24934aba92ec6c43d564061c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c1d10c7a472146e6bc09d22632fd848e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_deb6986103c4477cad2b07f7a5ea4974",
       "IPY_MODEL_a1653abe0c694d5d8676a4c09bfe5800"
      ],
      "layout": "IPY_MODEL_a5171886b4bc4c67b758ce052c1cee77"
     }
    },
    "ce6dcf9416d141c9b5d5ad1e6394b621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deb6986103c4477cad2b07f7a5ea4974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90a2ffa504ff42329da39e7c1497c888",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b18f211b24934aba92ec6c43d564061c",
      "value": 1
     }
    },
    "dec70d900ac442138b73f1d58da684af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84107f986d5b45bfb4d9a9c9f934d1de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f37affbd69e486dad7cddeb8c8c9cb5",
      "value": 1
     }
    },
    "e65e31421f9b40d4a3c59f36622e3163": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f369bec9f8ff41338384dd48065e2d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce6dcf9416d141c9b5d5ad1e6394b621",
      "placeholder": "​",
      "style": "IPY_MODEL_4725f0f119e04f81a780a2489a8ef8dd",
      "value": " 1654784/? [00:18&lt;00:00, 546804.35it/s]"
     }
    },
    "f9f8b1e0739844809134cba5ab30e74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dec70d900ac442138b73f1d58da684af",
       "IPY_MODEL_f369bec9f8ff41338384dd48065e2d59"
      ],
      "layout": "IPY_MODEL_4722aa0e04264c76964d58b5e3a65a32"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
